description: VLA BridgeRT Mistral-7B-zero3 Vision Action Feature, submission of qilinzhang, using peft
env_defaults:
  NODES: 1 # The number of nodes you want to use
  GPUS: 8 # number of gpus per node
  MEM: 40 # gpu memory of each gpu, not important

target:
  service: sing # for singularity, no need to change
  workspace_name: wsgcrrbt # our workspace to use singularity, no need to change
  name: msroctovc # change for different kinds of gpus. The detailed quota can be checked with command "amlt ti sing -v"

storage: # mount the storage container
  my_output:
    storage_account_name: azsussc
    container_name: v-rundongluo
    mount_dir: /mnt/data-rundong

environment: # select the image, clone your code, install the packages
  image: base/job/pytorch/acpt-2.1.2-cuda11.8:20240320T154353549
  setup:
    - pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
    - git clone https://github.com/Zenobiaql/VLA.git && cd VLA
    - pip install -r requirements.txt
  registry: singularitybase.azurecr.io # cached base images under amlt-sing/* seems not usable now, use singularitybase instead

code:
  local_dir: $CONFIG_DIR/

data:
  storage_id: my_output

jobs:
  - name: PEFT-LoRA-rank64-alpha128 # the job name you will see on the portal. Though not important, you'd better carefully set it for clarity.
    sku: ${NODES}x${MEM}G${GPUS}-A100-IB # determinate the GPU you will use, please refer to the official docs for more information 
    process_count_per_node: 1 # usually 1
    sla_tier: Standard # Premium, Standard, Basic. corresponding to the priority.
    execution_mode: basic
    identity: managed
    submit_args:
      env:
        AMLT_DOCKERFILE_TEMPLATE: default
        _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/3289a5dd-b901-4b63-9562-bbbdfffba9de/resourcegroups/ws/providers/Microsoft.ManagedIdentity/userAssignedIdentities/wsgcrrbt-identity
        SHARED_MEMORY_PERCENT: 0.5 # value in [0,1], change if necessary, shared memory size

    command:
      - cd VLA
      - torchrun --nproc_per_node=$GPUS --nnode=$NODES --node_rank=$$AZUREML_CR_NODE_RANK --master_addr=$$AZ_BATCHAI_JOB_MASTER_NODE_IP --master_port=9901 scripts/train_peft.py configs/mistral/config_zero3_woVision_wotext_1217debug.yaml